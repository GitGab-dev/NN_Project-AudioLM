{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SoundStream import soundstream_16khz, audio_to_tokens, tokens_to_audio\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most of the tokens have an equal measure of:\n",
      "Coarse: 1503\n",
      "Fine: 2505\n"
     ]
    }
   ],
   "source": [
    "model = soundstream_16khz()\n",
    "\n",
    "\n",
    "audio_paths = {f'./data_cut/14/342/canterburytales_09_chaucer_64kb_000{i}.flac' for i in range(6)}\n",
    "audio_paths.update({f'./data_cut/16/342/canterburytales_24_chaucer_64kb_000{i}.flac' for i in range(10)})\n",
    "audio_paths.update({f'./data_cut/16/352/little_lame_prince_01_64kb_000{i}.flac' for i in range(10)})\n",
    "audio_paths.update({f'./data_cut/16/352/little_lame_prince_01_64kb_001{i}.flac' for i in range(5)})\n",
    "audio_paths.update({f'./data_cut/16/352/little_lame_prince_02_64kb_000{i}.flac' for i in range(10)})\n",
    "audio_paths.update({f'./data_cut/16/352/little_lame_prince_02_64kb_001{i}.flac' for i in range(9)})\n",
    "audio_paths.update({f'./data_cut/16/352/little_lame_prince_03_64kb_000{i}.flac' for i in range(7)})\n",
    "\n",
    "start = 5\n",
    "duration = 10\n",
    "\n",
    "previouse_coarse_shape = None\n",
    "previouse_fine_shape = None\n",
    "equals = True\n",
    "for audio_path in audio_paths:\n",
    "\twaveform, sample_rate = torchaudio.load(audio_path)\n",
    "\tnum_samples = waveform.size(1)  # waveform is a tensor of shape (num_channels, num_samples)\n",
    "\taudio_duration = num_samples / sample_rate\n",
    "\n",
    "\tcoarse, fine = audio_to_tokens(waveform, sample_rate, model, start, duration)\n",
    "\tif previouse_coarse_shape == None:\n",
    "\t\tpreviouse_coarse_shape = coarse.shape[0]\n",
    "\t\tpreviouse_fine_shape = fine.shape[0]\n",
    "\telse:\n",
    "\t\tif previouse_coarse_shape != coarse.shape[0] or previouse_fine_shape != fine.shape[0]:\n",
    "\t\t\tprint(\"Prevoius: \" + str(previouse_coarse_shape) + \"  \" + str(previouse_fine_shape) + \"\\nCurrent: \" + str(coarse.shape[0]) + \" \" + str(fine.shape[0]))\n",
    "\t\t\tprint(audio_path)\n",
    "\t\t\tif(audio_duration < start + duration):\n",
    "\t\t\t\tprint(\"Audio duration lesser than cut\")\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tequals = False\n",
    "\t\t\tbreak\n",
    "\n",
    "if equals:\n",
    "\tprint(\"Most of the tokens have an equal measure of:\\nCoarse: \" + str(previouse_coarse_shape) + \"\\nFine: \" + str(previouse_fine_shape))\n",
    "else:\n",
    "\tprint(\"The tokens have a different size\")\n",
    "\n",
    "#audio = tokens_to_audio(coarse, fine, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
