{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SoundStream import soundstream_16khz, audio_to_tokens, tokens_to_audio\n",
    "import torchaudio\n",
    "import torch\n",
    "from hubertKM import SemanticTokenizer, visualizeEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/hubert-base-ls960 were not used when initializing HubertModel: ['encoder.pos_conv_embed.conv.weight_g', 'encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing HubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertModel were not initialized from the model checkpoint at facebook/hubert-base-ls960 and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\fabri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MiniBatchKMeans from version 0.24.0 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most of the tokens have an equal measure of:\n",
      "Coarse: 4503\n",
      "Fine: 7505\n",
      "Semantic: 1499\n"
     ]
    }
   ],
   "source": [
    "model = soundstream_16khz()\n",
    "\n",
    "w2vBERT = SemanticTokenizer(\"facebook/hubert-base-ls960\",\"./hubertKM/hubert_base_ls960_L9_km500.bin\")  \n",
    "\n",
    "audio_paths = {f'./data_cut/14/342/canterburytales_09_chaucer_64kb_000{i}.flac' for i in range(6)}\n",
    "\n",
    "#audio_paths.update({f'./data_cut/16/342/canterburytales_24_chaucer_64kb_000{i}.flac' for i in range(10)})\n",
    "#audio_paths.update({f'./data_cut/16/352/little_lame_prince_01_64kb_000{i}.flac' for i in range(10)})\n",
    "#audio_paths.update({f'./data_cut/16/352/little_lame_prince_01_64kb_001{i}.flac' for i in range(5)})\n",
    "#audio_paths.update({f'./data_cut/16/352/little_lame_prince_02_64kb_000{i}.flac' for i in range(10)})\n",
    "#audio_paths.update({f'./data_cut/16/352/little_lame_prince_02_64kb_001{i}.flac' for i in range(9)})\n",
    "#audio_paths.update({f'./data_cut/16/352/little_lame_prince_03_64kb_000{i}.flac' for i in range(7)})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start = 0\n",
    "duration = 30\n",
    "\n",
    "previouse_coarse_shape = None\n",
    "previouse_fine_shape = None\n",
    "previouse_semantic_shape = None\n",
    "equals = True\n",
    "for audio_path in audio_paths:\n",
    "\twaveform, sample_rate = torchaudio.load(audio_path)\n",
    "\n",
    "\tx, sample_rate = torchaudio.functional.resample(waveform, sample_rate, 16000), 16000\n",
    "\n",
    "\twaveform = x[:, start*16000:(start + duration)*16000]\n",
    "\n",
    "\tnum_samples = waveform.size(1)  # waveform is a tensor of shape (num_channels, num_samples)\n",
    "\taudio_duration = num_samples / sample_rate\n",
    "\twith torch.no_grad():\n",
    "\t\tsemanticTokens, _ = w2vBERT(waveform)\n",
    "\tcoarse, fine = audio_to_tokens(waveform, sample_rate, model, start, duration)\n",
    "\tif previouse_coarse_shape == None:\n",
    "\t\tpreviouse_coarse_shape = coarse.shape[0]\n",
    "\t\tpreviouse_fine_shape = fine.shape[0]\n",
    "\t\tpreviouse_semantic_shape = semanticTokens.shape[0]\n",
    "\telse:\n",
    "\t\tif previouse_coarse_shape != coarse.shape[0] or previouse_fine_shape != fine.shape[0] or previouse_semantic_shape != semanticTokens.shape[0]:\n",
    "\t\t\tprint(\"Prevoius: \" + str(previouse_coarse_shape) + \"  \" + str(previouse_fine_shape) + \"\\nCurrent: \" + str(coarse.shape[0]) + \" \" + str(fine.shape[0]))\n",
    "\t\t\tprint(audio_path)\n",
    "\t\t\tif(audio_duration < start + duration):\n",
    "\t\t\t\tprint(\"Audio duration lesser than cut\")\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tequals = False\n",
    "\t\t\tbreak\n",
    "\n",
    "if equals:\n",
    "\tprint(\"Most of the tokens have an equal measure of:\\nCoarse: \" + str(previouse_coarse_shape) + \"\\nFine: \" + str(previouse_fine_shape) + \"\\nSemantic: \" + str(previouse_semantic_shape))\n",
    "else:\n",
    "\tprint(\"The tokens have a different size\")\n",
    "\n",
    "#audio = tokens_to_audio(coarse, fine, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
