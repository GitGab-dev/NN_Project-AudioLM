{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d86e3b5",
   "metadata": {},
   "source": [
    "## 0. Colab Code"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9d46ab8",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "!pip install pytorch_lightning\n",
    "\n",
    "!cd ./drive/\"My Drive\"/AudioLM\n",
    "import sys\n",
    "sys.path.append('./drive/My Drive/AudioLM')\n",
    "%cd ./drive/MyDrive/AudioLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ac72ac",
   "metadata": {},
   "source": [
    "## 1. Preparing the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d969b6d-c5f6-4512-8b78-da455c31205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531721cf-9b1a-4508-b273-fe9f0aec0c42",
   "metadata": {},
   "source": [
    "## 0.5. Creating the Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ec794d2-d86a-41ba-b429-9ecf4ec4aef9",
   "metadata": {},
   "source": [
    "from torchaudio.transforms import Resample\n",
    "from data import LibriDataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c83fee74-8f20-4303-a45a-0f675e8a4fd3",
   "metadata": {},
   "source": [
    "SAMPLE_FREQ = 16000\n",
    "AUDIO_MAX_DURATION = 60\n",
    "BATCH_SIZE = 12\n",
    "\n",
    "# Creating the dataset and dataloader\n",
    "\n",
    "trainDataset = LibriDataset(\"data_cut\", newSampleFreq = SAMPLE_FREQ, maxLenght = SAMPLE_FREQ * AUDIO_MAX_DURATION)\n",
    "trainDataLoader = DataLoader(trainDataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5af4cea-6b17-4859-a09c-6fc37ec42540",
   "metadata": {},
   "source": [
    "print(\"Audio in the dataset: \" + str(len(trainDataset)))\n",
    "print(\"Frame per item: \" + str(trainDataset[2][0].shape))\n",
    "Audio(trainDataset[40][0], rate = SAMPLE_FREQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5b93c2-1d22-4982-aab2-562274398151",
   "metadata": {},
   "source": [
    "## 2. HuBERT TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635a0dbe-037b-470f-b01c-5887976860f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fabri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import HubertModel,AutoProcessor,AutoFeatureExtractor,Wav2Vec2Processor,HubertForCTC\n",
    "import joblib\n",
    "import torch.nn as nn\n",
    "from hubertKM import SemanticTokenizer, visualizeEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08a10e9-11a5-4601-b3ba-70eb184dd05c",
   "metadata": {},
   "source": [
    "#### Importing the pretrained models for HuBERT and KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55c8472c-751a-4ff1-9d61-563c36a98790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/hubert-base-ls960 were not used when initializing HubertModel: ['encoder.pos_conv_embed.conv.weight_g', 'encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing HubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertModel were not initialized from the model checkpoint at facebook/hubert-base-ls960 and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\fabri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MiniBatchKMeans from version 0.24.0 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# A semantic tokenizer\n",
    "# Input: (w2vCheckpointPath, kmeansCheckpointPath)\n",
    "# Output: (semanticTokens, normalizedEmbeddings)\n",
    "w2vBERT = SemanticTokenizer(\"facebook/hubert-base-ls960\",\"./hubertKM/hubert_base_ls960_L9_km500.bin\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1684140-30bb-42f2-946d-52ac096687d6",
   "metadata": {},
   "source": [
    "#### Computing semantic tokens"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c07ccfc-c2e2-4ea4-be30-5f920ef898e8",
   "metadata": {},
   "source": [
    "with torch.no_grad():\n",
    "    s = time.time()\n",
    "    ##semanticTokens, embeddings = w2vBERT(trainDataset[0])\n",
    "    #semanticTokens, embeddings = w2vBERT(next(iter(trainDataLoader)).squeeze())\n",
    "    print(time.time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd526997-2dff-4ae2-a41e-8a8614df9b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#semanticTokens, embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800ce5db-e321-489d-9b96-0c4bcf9376eb",
   "metadata": {},
   "source": [
    "#### Visualizing embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e177c2c7-b8a4-445c-a09f-1f34d824d45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some plots using PCA and t-SNE\n",
    "\n",
    "# visualizeEmbeddings(embeddings, semanticTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff33d1b-c960-460b-9bb7-8e93c0a15df2",
   "metadata": {},
   "source": [
    "#### Check with another implementation (OPTIONAL)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "715088b1-2e62-47d1-80ac-f7a0dfef4551",
   "metadata": {},
   "source": [
    "# Models from https://github.com/lucidrains/audiolm-pytorch\n",
    "\n",
    "!pip install audiolm-pytorch"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d561d1f-f1a4-4ab1-904a-efe839265162",
   "metadata": {},
   "source": [
    "from audiolm_pytorch import HubertWithKmeans\n",
    "\n",
    "wav2vec = HubertWithKmeans(\n",
    "    checkpoint_path = './hubertKM/hubert_base_ls960.pt',\n",
    "    kmeans_path = './hubertKM/hubert_base_ls960_L9_km500.bin'\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15ef3d89-a05a-4475-82d5-02ff82b5245c",
   "metadata": {},
   "source": [
    "with torch.no_grad():\n",
    "    s = time.time()\n",
    "    ##semanticTokens = w2vBERT(trainDataset[1])\n",
    "    s2 = time.time()\n",
    "    #semanticTokensAlt = wav2vec(next(iter(trainDataLoader)).squeeze())\n",
    "    s3 = time.time()\n",
    "\n",
    "    print(s3-s2,s2-s)\n",
    "    \n",
    "# Test if tokens are equal\n",
    "#tokensEqualityTest = not (semanticTokensAlt.squeeze() - semanticTokens).any()\n",
    "#tokensEqualityTest 6.852179765701294 7.743693113327026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bede15-a67d-4b38-a185-f9e85473598b",
   "metadata": {},
   "source": [
    "## 3. Creating the Semantic Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f784d68d-8afe-4968-800c-a96c628e29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SoundStream import soundstream_16khz, audio_to_tokens, tokens_to_audio, encode_audio, decode_audio"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe2ad079-ab89-4176-8da4-b7e3476fb04d",
   "metadata": {},
   "source": [
    "Audio(trainDataset[40][0], rate = SAMPLE_FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b64f910b-93b3-4abc-b1c5-9eb1ed6c8f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "soundStream = soundstream_16khz()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "08227788-64dd-4a3c-9909-8cf3c2c6485e",
   "metadata": {},
   "source": [
    "audioWave, sampleRate = torchaudio.load(\"data_cut\\\\16\\\\352\\\\little_lame_prince_01_64kb_0000.flac\")\n",
    "\n",
    "x = encode_audio(audioWave, sampleRate, soundStream)\n",
    "print(x.shape)\n",
    "Audio(audioWave, rate = sampleRate)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb41d156-9384-4b0d-b5c7-7ee0a52375d7",
   "metadata": {},
   "source": [
    "x = soundStream.encode(audioWave)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b444731-3eb4-4e34-b6fb-252feb95e326",
   "metadata": {},
   "source": [
    "# x = soundStream.encode(next(iter(trainDataLoader)).squeeze())\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e75da434-f1aa-4b5a-b2a1-920cfe8cd13d",
   "metadata": {},
   "source": [
    "coarse, fine = audio_to_tokens(audioWave, sampleRate, soundStream)\n",
    "print(coarse.shape, fine.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36665ad3-1dc6-4f2b-b425-608148c2d012",
   "metadata": {},
   "source": [
    "y = decode_audio(x, soundStream)\n",
    "print(x)\n",
    "Audio(y, rate = SAMPLE_FREQ)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70f19546-7dce-4dff-ae24-5cc95627e69e",
   "metadata": {},
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da3cedff-5c31-463c-b8e3-874dad36d607",
   "metadata": {},
   "source": [
    "y2 = tokens_to_audio(coarse, fine, soundStream)\n",
    "Audio(y2, rate = SAMPLE_FREQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15243c0d-d248-430c-abbe-6ae2d00f3de9",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8645e6c7-2eb6-46c4-9080-3325f3a7bef6",
   "metadata": {},
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from IPython.display import Audio\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8c804da-5b7d-47b5-af6a-171fed52a19e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def storeTokens(audioDir, outDir, w2vBERT, soundStream, fileCountCheckpoint = 5):\n",
    "\n",
    "    Path(outDir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    isNewFile = not os.path.exists(os.path.join(outDir, \"out.csv\"))\n",
    "\n",
    "    ## Check for eventual checkpoints\n",
    "    fileChecked = 0\n",
    "    reachedCheckpoint = False\n",
    "    lastFile = None\n",
    "    \n",
    "    if os.path.exists(os.path.join(outDir, \"checkpoint.txt\")):\n",
    "        with open(os.path.join(outDir, \"checkpoint.txt\"), mode='r', newline='') as checkpointFile:\n",
    "            \n",
    "            fileChecked, lastFile = checkpointFile.readline().strip().split(\" \")\n",
    "            fileChecked = int(fileChecked)\n",
    "            print(\"Found a checkpoint!\")\n",
    "\n",
    "    tokenData = []\n",
    "    fileCount = 0\n",
    "\n",
    "    totalFiles = 0\n",
    "    for root, dirs, files in os.walk(audioDir):\n",
    "        totalFiles += len(files)\n",
    "\n",
    "    with tqdm(total=totalFiles, desc='Processing files') as pbar:\n",
    "        for root, dirs, files in os.walk(audioDir):\n",
    "            for file in files:\n",
    "    \n",
    "                reachedCheckpoint = (fileChecked == 0 or file == lastFile or reachedCheckpoint)\n",
    "                \n",
    "                if file.endswith(\".flac\") and reachedCheckpoint and file != lastFile:\n",
    "              \n",
    "                    file_path = os.path.join(root, file)\n",
    "                    waveform, sr = torchaudio.load(file_path)\n",
    "                    with torch.no_grad():\n",
    "                        semanticTokens, _ = w2vBERT(waveform)\n",
    "                        coarseTokens, fineTokens = audio_to_tokens(waveform, sr, soundStream)\n",
    "                        \n",
    "                    tokenData.append([file, semanticTokens.tolist(), coarseTokens.tolist(), fineTokens.tolist()])\n",
    "    \n",
    "                    fileCount += 1\n",
    "    \n",
    "                if fileCount % fileCountCheckpoint == 0 and reachedCheckpoint and file != lastFile:\n",
    "                    with open(os.path.join(outDir, \"out.csv\"), mode='a', newline='') as outFile, open(os.path.join(outDir, \"checkpoint.txt\"), mode='w', newline='') as checkpointFile:\n",
    "                        writer = csv.writer(outFile, delimiter = \";\")\n",
    "    \n",
    "                        ## Add header in case of newFile\n",
    "                        if isNewFile:\n",
    "                            outFile.write(\"sep=;\\n\")\n",
    "                            writer.writerow([\"fileName\", \"semanticTokens\", \"coarseTokens\", \"fineTokens\"])\n",
    "                            isNewFile = not isNewFile\n",
    "                            \n",
    "                        writer.writerows(tokenData)\n",
    "    \n",
    "                        checkpointFile.write(f\"{fileCount + fileChecked} {file}\")\n",
    "                        \n",
    "                    print(f\"SAVED {fileCount} AUDIO ON OUTPUT {os.path.join(outDir, 'out.csv')}. Total of {fileCount + fileChecked} records saved.\") \n",
    "                    tokenData = []\n",
    "                    \n",
    "                pbar.update(1) \n",
    "\n",
    "    return fileCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "363d987c-7c31-47c6-8b1d-0ab854622237",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data import storeTokens,  TokensDataset, store_from_librilight\n",
    "\n",
    "tokenPath = \"out\"\n",
    "tokenFile = \"out.csv\"\n",
    "audioPath = \"data_cut\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ccb6662-f99c-4183-a70e-2f254a2f44f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fileCount \u001b[38;5;241m=\u001b[39m \u001b[43mstore_from_librilight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenPath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenFile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw2vBERT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoundStream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfileCountCheckpoint\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fabri\\Documents\\GitHub\\NN_Project-AudioLM\\data.py:222\u001b[0m, in \u001b[0;36mstore_from_librilight\u001b[1;34m(outDir, outFile, w2vBERT, soundStream, fileCountCheckpoint)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(outDir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(outDir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m checkpointFile:\n\u001b[1;32m--> 222\u001b[0m         fileChecked, lastFile \u001b[38;5;241m=\u001b[39m checkpointFile\u001b[38;5;241m.\u001b[39mreadline()\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    223\u001b[0m         fileChecked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(fileChecked)\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound a checkpoint!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "#fileCount = store_from_librilight(tokenPath, tokenFile, w2vBERT, soundStream, fileCountCheckpoint = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c254dc63-ffc3-4da7-ae8b-116b4617c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenDataset = TokensDataset(tokenPath, tokenFile, requiredDuration = 30, includeSemanticTokens = True, includeCoarseTokens = True, includeFineTokens = True) \n",
    "#semanticDataset = TokensDataset(tokenPath, tokenFile, requiredDuration = 30, includeSemanticTokens = True)\n",
    "coarseDataset = TokensDataset(tokenPath, tokenFile, requiredDuration = 10, includeCoarseTokens = True)\n",
    "#fineDataset = TokensDataset(tokenPath, tokenFile, requiredDuration = 30, includeFineTokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b95387c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from TransformerModel import Decoder\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99f4e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = semanticDataset\n",
    "train_dataset = coarseDataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5ee5ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Change vocab_size and seq_len to initiate, k should be d_model/num_heads\n",
    "model = Decoder( d_model=256, num_layers = 3, num_heads=4, dim_feedforward=1024, dropout=0.1, k=64, vocab_size=10000, seq_len=1503)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "713d2a52",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Callbacks for saving the best model and early stopping\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Trainer configuration\n",
    "trainer = pl.Trainer(\n",
    "\tcallbacks=[checkpoint_callback],\n",
    "    max_epochs=10,  # Set the number of epochs\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',  # Use GPU if available\n",
    "    devices=1 if torch.cuda.is_available() else 1,  # Number of devices for both GPU and CPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2360cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\fabri\\AppData\\Local\\Temp\\ipykernel_17196\\3180745041.py:3: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  checkpoint = torch.load(\"checkpoints\\checkpoint_epoch_10.pt\")\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"checkpoints\\checkpoint_epoch_10.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b47b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb44b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[  85, 1245, 2766,  ...,  476, 1325, 2570]]), tensor([[1245, 2766,  556,  ..., 1325, 2570, -100]]))\n"
     ]
    }
   ],
   "source": [
    "#model.eval()\n",
    "x_input = coarseDataset.__getitem__(0)\n",
    "\n",
    "print(x_input)\n",
    "with torch.no_grad():\n",
    "\tpredictions = model(x_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ad940f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1720)\n",
      "tensor(2483)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(2317)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(1076)\n",
      "tensor(2317)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(1989)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1720)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(919)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(507)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(2317)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(436)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(773)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(2031)\n",
      "tensor(822)\n",
      "tensor(1989)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(2317)\n",
      "tensor(787)\n",
      "tensor(227)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(436)\n",
      "tensor(2668)\n",
      "tensor(1076)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(2317)\n",
      "tensor(227)\n",
      "tensor(773)\n",
      "tensor(2317)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(2317)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(1217)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(1263)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(1241)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(2317)\n",
      "tensor(514)\n",
      "tensor(1241)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(1989)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(2317)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(919)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(1988)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(787)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(2317)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(436)\n",
      "tensor(514)\n",
      "tensor(1241)\n",
      "tensor(2317)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(2317)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(1902)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(436)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(2317)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(1076)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(919)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(1720)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(751)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(2317)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(1720)\n",
      "tensor(822)\n",
      "tensor(1989)\n",
      "tensor(436)\n",
      "tensor(436)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(2317)\n",
      "tensor(787)\n",
      "tensor(227)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(2483)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(227)\n",
      "tensor(2031)\n",
      "tensor(822)\n",
      "tensor(2317)\n",
      "tensor(787)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(436)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(997)\n",
      "tensor(822)\n",
      "tensor(507)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(2668)\n",
      "tensor(822)\n",
      "tensor(2317)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(2317)\n",
      "tensor(787)\n",
      "tensor(1260)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1263)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(773)\n",
      "tensor(2031)\n",
      "tensor(1260)\n",
      "tensor(822)\n",
      "tensor(507)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(919)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(787)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(227)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(79)\n",
      "tensor(919)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(787)\n",
      "tensor(787)\n",
      "tensor(461)\n",
      "tensor(787)\n",
      "tensor(787)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(773)\n",
      "tensor(2653)\n",
      "tensor(514)\n",
      "tensor(1241)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(2317)\n",
      "tensor(822)\n",
      "tensor(1720)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(1988)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(1720)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(919)\n",
      "tensor(773)\n",
      "tensor(1341)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(787)\n",
      "tensor(1241)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(227)\n",
      "tensor(1730)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(79)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(787)\n",
      "tensor(436)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(1241)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(436)\n",
      "tensor(1989)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(227)\n",
      "tensor(2317)\n",
      "tensor(822)\n",
      "tensor(2031)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1989)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1217)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(2653)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(773)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(227)\n",
      "tensor(1217)\n",
      "tensor(997)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(2796)\n",
      "tensor(514)\n",
      "tensor(1275)\n",
      "tensor(436)\n",
      "tensor(321)\n",
      "tensor(787)\n",
      "tensor(787)\n",
      "tensor(773)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(2317)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(227)\n",
      "tensor(1217)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(787)\n",
      "tensor(262)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(1056)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(919)\n",
      "tensor(787)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(919)\n",
      "tensor(507)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(1730)\n",
      "tensor(1241)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(436)\n",
      "tensor(2317)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(321)\n",
      "tensor(79)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1720)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(2031)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(514)\n",
      "tensor(1988)\n",
      "tensor(822)\n",
      "tensor(2668)\n",
      "tensor(1064)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(2317)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(227)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(1076)\n",
      "tensor(773)\n",
      "tensor(1241)\n",
      "tensor(436)\n",
      "tensor(1989)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(1275)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(227)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(787)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(330)\n",
      "tensor(751)\n",
      "tensor(2317)\n",
      "tensor(514)\n",
      "tensor(227)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(436)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(227)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1260)\n",
      "tensor(2483)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(1989)\n",
      "tensor(1988)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(1217)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(1217)\n",
      "tensor(514)\n",
      "tensor(1056)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(1241)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(1217)\n",
      "tensor(2317)\n",
      "tensor(773)\n",
      "tensor(1217)\n",
      "tensor(436)\n",
      "tensor(919)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(2031)\n",
      "tensor(2317)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(919)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(2028)\n",
      "tensor(2317)\n",
      "tensor(822)\n",
      "tensor(1989)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(1988)\n",
      "tensor(2483)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(2317)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(227)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(2285)\n",
      "tensor(514)\n",
      "tensor(1217)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(85)\n",
      "tensor(787)\n",
      "tensor(2317)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(2031)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(227)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(787)\n",
      "tensor(1727)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(919)\n",
      "tensor(822)\n",
      "tensor(919)\n",
      "tensor(79)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(1720)\n",
      "tensor(1260)\n",
      "tensor(514)\n",
      "tensor(1260)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(1241)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(1217)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(2317)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(2317)\n",
      "tensor(514)\n",
      "tensor(1260)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(227)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(1217)\n",
      "tensor(2483)\n",
      "tensor(514)\n",
      "tensor(1217)\n",
      "tensor(2317)\n",
      "tensor(773)\n",
      "tensor(1217)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(1056)\n",
      "tensor(2317)\n",
      "tensor(514)\n",
      "tensor(1217)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(1056)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1217)\n",
      "tensor(1241)\n",
      "tensor(773)\n",
      "tensor(1241)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(1241)\n",
      "tensor(436)\n",
      "tensor(227)\n",
      "tensor(1241)\n",
      "tensor(436)\n",
      "tensor(514)\n",
      "tensor(1687)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(79)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(436)\n",
      "tensor(1260)\n",
      "tensor(514)\n",
      "tensor(436)\n",
      "tensor(514)\n",
      "tensor(2285)\n",
      "tensor(751)\n",
      "tensor(787)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(919)\n",
      "tensor(1989)\n",
      "tensor(227)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(1217)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(1217)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1076)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(227)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(1773)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(1989)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(2796)\n",
      "tensor(773)\n",
      "tensor(1241)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(787)\n",
      "tensor(787)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(363)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(1988)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(227)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(919)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(2317)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1720)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(1076)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(2317)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(2796)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(2317)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(1988)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(1341)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(79)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(773)\n",
      "tensor(787)\n",
      "tensor(1720)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(1988)\n",
      "tensor(2317)\n",
      "tensor(1989)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(227)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(1217)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(227)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(2044)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(1341)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(1)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(997)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(2317)\n",
      "tensor(436)\n",
      "tensor(773)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1076)\n",
      "tensor(227)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(227)\n",
      "tensor(773)\n",
      "tensor(1260)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(1241)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(227)\n",
      "tensor(436)\n",
      "tensor(514)\n",
      "tensor(227)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(227)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(1076)\n",
      "tensor(2317)\n",
      "tensor(787)\n",
      "tensor(1056)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(1056)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(436)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1056)\n",
      "tensor(514)\n",
      "tensor(436)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(227)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(436)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(2847)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(227)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(3055)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(2031)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(2317)\n",
      "tensor(436)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(262)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(1687)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(919)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(773)\n",
      "tensor(787)\n",
      "tensor(227)\n",
      "tensor(1241)\n",
      "tensor(227)\n",
      "tensor(514)\n",
      "tensor(1217)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(1217)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(919)\n",
      "tensor(1988)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(436)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(2317)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(2668)\n",
      "tensor(436)\n",
      "tensor(507)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(1720)\n",
      "tensor(1260)\n",
      "tensor(514)\n",
      "tensor(227)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(1470)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(787)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(773)\n",
      "tensor(787)\n",
      "tensor(773)\n",
      "tensor(773)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(919)\n",
      "tensor(1989)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(1730)\n",
      "tensor(787)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(1341)\n",
      "tensor(2847)\n",
      "tensor(514)\n",
      "tensor(1241)\n",
      "tensor(2317)\n",
      "tensor(514)\n",
      "tensor(1988)\n",
      "tensor(2847)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1988)\n",
      "tensor(919)\n",
      "tensor(822)\n",
      "tensor(1056)\n",
      "tensor(822)\n",
      "tensor(1260)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(919)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(773)\n",
      "tensor(822)\n",
      "tensor(2317)\n",
      "tensor(822)\n",
      "tensor(507)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(507)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(1720)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(1988)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(1144)\n",
      "tensor(919)\n",
      "tensor(514)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(436)\n",
      "tensor(1217)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(919)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(514)\n",
      "tensor(1341)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(1263)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(1241)\n",
      "tensor(227)\n",
      "tensor(773)\n",
      "tensor(919)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(2317)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(227)\n",
      "tensor(436)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(227)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(919)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(787)\n",
      "tensor(822)\n",
      "tensor(514)\n",
      "tensor(822)\n",
      "tensor(822)\n",
      "tensor(514)\n"
     ]
    }
   ],
   "source": [
    "pred = torch.argmax(predictions, dim=-1)\n",
    "for elem in pred[0]:\n",
    "\tprint(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb4632",
   "metadata": {},
   "outputs": [],
   "source": [
    "fineDataset = TokensDataset(tokenPath, tokenFile, requiredDuration = 10, includeFineTokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e21798b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2505])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_input = fineDataset.__getitem__(0)[0]\n",
    "\n",
    "y_input = y_input.squeeze(0)\n",
    "pred_new = pred.squeeze(0)\n",
    "#waveform = tokens_to_audio(pred_new, y_input, soundStream)\n",
    "y_input.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
